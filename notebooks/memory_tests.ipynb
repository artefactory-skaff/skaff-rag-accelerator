{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "sys.path.append(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chat_models.base import SystemMessage, HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.vectorstores import VectorStore\n",
    "from langchain.memory.chat_message_histories import SQLChatMessageHistory\n",
    "\n",
    "from backend.config_renderer import get_config\n",
    "from backend.rag_components.embedding import get_embedding_model\n",
    "from backend.rag_components.llm import get_llm_model\n",
    "from backend.rag_components.vector_store import get_vector_store\n",
    "import frontend.lib.auth as auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_chain(llm, docsearch: VectorStore, memory) -> ConversationalRetrievalChain:\n",
    "    \"\"\"Returns an instance of ConversationalRetrievalChain based on the provided parameters.\"\"\"\n",
    "    template = \"\"\"Given the conversation history and the following question, can you rephrase the user's question in its original language so that it is self-sufficient. Make sure to avoid the use of unclear pronouns.\n",
    "\n",
    "Chat history :\n",
    "{chat_history}\n",
    "Question : {question}\n",
    "\n",
    "Rephrased question :\n",
    "\"\"\"\n",
    "    condense_question_prompt = PromptTemplate.from_template(template)\n",
    "    condense_question_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=condense_question_prompt,\n",
    "    )\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"\"\"As a chatbot assistant, your mission is to respond to user inquiries in a precise and concise manner based on the documents provided as input. It is essential to respond in the same language in which the question was asked. Responses must be written in a professional style and must demonstrate great attention to detail.\"\"\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessage(content=\"Respond to the question taking into account the following context.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{context}\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"Question: {question}\"),\n",
    "    ]\n",
    "    system_prompt = ChatPromptTemplate(messages=messages)\n",
    "    qa_chain = LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=system_prompt,\n",
    "    )\n",
    "\n",
    "    doc_prompt = PromptTemplate(\n",
    "        template=\"Content: {page_content}\\nSource: {source}\",\n",
    "        input_variables=[\"page_content\", \"source\"],\n",
    "    )\n",
    "\n",
    "    final_qa_chain = StuffDocumentsChain(\n",
    "        llm_chain=qa_chain,\n",
    "        document_variable_name=\"context\",\n",
    "        document_prompt=doc_prompt,\n",
    "    )\n",
    "\n",
    "    return ConversationalRetrievalChain(\n",
    "        question_generator=condense_question_chain,\n",
    "        retriever=docsearch.as_retriever(search_kwargs={\"k\": 10}),\n",
    "        memory=memory,\n",
    "        combine_docs_chain=final_qa_chain,\n",
    "        verbose=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "llm = get_llm_model(config)\n",
    "embeddings = get_embedding_model(config)\n",
    "vector_store = get_vector_store(embeddings, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \"slauzeral\"\n",
    "password = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "success = auth.sign_up(username, password)\n",
    "if success:\n",
    "    token = auth.get_token(username, password)\n",
    "    session = auth.create_session()\n",
    "    auth_session = auth.authenticate_session(session, token)\n",
    "\n",
    "response = auth_session.post(\"/chat/new\")\n",
    "chat_id = response.json()[\"chat_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from uuid import uuid4\n",
    "from typing import Any\n",
    "\n",
    "from langchain.memory.chat_message_histories.sql import DefaultMessageConverter\n",
    "from langchain.schema import AIMessage, BaseMessage, HumanMessage, SystemMessage\n",
    "from sqlalchemy import Column, DateTime, Integer, Text\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from langchain.schema.messages import BaseMessage, _message_to_dict, messages_from_dict\n",
    "import json\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class CustomMessage(Base):\n",
    "    __tablename__ = \"message_test\"\n",
    "\n",
    "    id = Column(Text, primary_key=True,  default=lambda: str(uuid4())) # default=lambda: str(uuid4())\n",
    "    timestamp = Column(DateTime)\n",
    "    chat_id = Column(Text)\n",
    "    sender = Column(Text)\n",
    "    content = Column(Text)\n",
    "    message = Column(Text)\n",
    "\n",
    "\n",
    "class CustomMessageConverter(DefaultMessageConverter):\n",
    "\n",
    "    def to_sql_model(self, message: BaseMessage, session_id: str) -> Any:\n",
    "        sub_message = json.loads(message.content)\n",
    "        return CustomMessage(\n",
    "            id = sub_message[\"id\"],\n",
    "            timestamp = datetime.strptime(sub_message[\"timestamp\"], \"%Y-%m-%d %H:%M:%S.%f\"),\n",
    "            chat_id = session_id,\n",
    "            sender = message.type,\n",
    "            content = sub_message[\"content\"],\n",
    "            message = json.dumps(_message_to_dict(message)),\n",
    "        )\n",
    "\n",
    "    def get_sql_model_class(self) -> Any:\n",
    "        return CustomMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_history = SQLChatMessageHistory(\n",
    "    session_id=chat_id,\n",
    "    connection_string=\"sqlite:////Users/sarah.lauzeral/Library/CloudStorage/GoogleDrive-sarah.lauzeral@artefact.com/Mon Drive/internal_projects/skaff-rag-accelerator/database/database.sqlite\",\n",
    "    table_name=\"message_test\",\n",
    "    session_id_field_name=\"chat_id\",\n",
    "    custom_message_converter=CustomMessageConverter(table_name=\"message_test\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_message_history.add_ai_message(json.dumps({\"content\":\"Hi\", \"timestamp\":f\"{datetime.utcnow()}\", \"id\":\"764528762\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='{\"content\": \"Hi\", \"timestamp\": \"2023-12-20 16:26:23.672506\", \"id\": \"764528762\"}')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_message_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skaff-rag-accelerator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
